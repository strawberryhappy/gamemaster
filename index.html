<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>特徴点一致率計算</title>
    <script async src="https://docs.opencv.org/master/opencv.js" type="text/javascript"></script>
    <style>
        video {
            width: 640px;
            height: 480px;
            border: 1px solid black;
        }
        canvas {
            display: none; /* Canvasは非表示にする */
        }
    </style>
</head>
<body>
    <h1>カメラ映像と画像の特徴点一致率</h1>
    <video id="video" autoplay></video>
    <canvas id="canvas"></canvas>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const targetImage = new Image();
        targetImage.crossOrigin = "Anonymous"
        targetImage.src = './image/citizen.png'; // ここに比較する画像のパスを設定してください

        let videoStream;

        // カメラ映像の取得
        async function startCamera() {
            videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = videoStream;
            video.play();
            requestAnimationFrame(processFrame);
        }

        // フレーム処理と特徴点抽出
        async function processFrame() {
            if (video.paused || video.ended) return;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            const frameData = ctx.getImageData(0, 0, canvas.width, canvas.height);

            const { keypoints: videoKeypoints, descriptors: videoDescriptors } = extractFeatures(frameData);
            const { keypoints: imageKeypoints, descriptors: imageDescriptors } = await extractImageFeatures(targetImage);

            const matches = matchFeatures(videoDescriptors, imageDescriptors);
            const matchRate = calculateMatchRate(matches, videoKeypoints.size());

            console.log(`一致率: ${matchRate.toFixed(2)}%`);
            document.body.insertAdjacentHTML('beforeend', `<p>一致率: ${matchRate.toFixed(2)}%</p>`); // 一致率をHTMLに表示

            requestAnimationFrame(processFrame);
        }

        // 特徴点抽出関数
        function extractFeatures(image) {
            const src = cv.matFromImageData(image);
            const gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

            const orb = new cv.ORB();
            const keypoints = new cv.KeyPointVector();
            const descriptors = new cv.Mat();
            orb.detect(gray, keypoints);
            orb.compute(gray, keypoints, descriptors);

            src.delete();
            gray.delete();

            return { keypoints, descriptors };
        }

        // 画像からの特徴点抽出
        async function extractImageFeatures(image) {
            await new Promise((resolve) => {
                image.onload = resolve;
            });
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = image.width;
            canvas.height = image.height;
            ctx.drawImage(image, 0, 0);
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            return extractFeatures(imageData);
        }

        // 特徴点のマッチング
        function matchFeatures(descriptors1, descriptors2) {
            const matcher = new cv.BFMatcher(cv.NORM_HAMMING, true);
            const matches = new cv.DMatchVector();
            matcher.match(descriptors1, descriptors2, matches);
            return matches;
        }

        // 一致率の計算
        function calculateMatchRate(matches, totalKeypoints) {
            return (matches.size() / totalKeypoints) * 100;
        }

        // カメラを開始
        startCamera();
    </script>
</body>
</html>
