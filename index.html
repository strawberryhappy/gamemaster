<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>特徴点マッチング</title>
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
</head>
<body>
    <h1>カメラ映像と画像の特徴点マッチング</h1>
    <video id="video" autoplay></video>
     <canvas id="canvas"></canvas>  
     <canvas id="canvasOutput"></canvas>  
    <!-- 結果表示用の要素 -->
    <div>
        <div>市民: <span id="citizen">- %</span></div>
        <div>人狼: <span id="werewolf">- %</span></div>
    </div>
    <canvas id="_citizen"></canvas>
    <canvas id="_werewolf"></canvas>

    <script>
        class gamemaster {
            constructor(paths){
                this.video = document.getElementById("video");
                this.canvas = document.getElementById("canvas");

                this.intervalID;
            
                this.images = [];
                this.features = {};
                
                this.addFeatures(paths || ["citizen.png","werewolf.png"]);
            }

            addFeatures(imagePaths) {
                // 画像の読み込みプロミスを格納する配列
                let loadPromises = imagePaths.map(path => {
                    return new Promise(resolve => {
                        this.images.push(path);

                        let img = new Image();
                        img.src = path;
            
                        img.onload = () => {
                            this.canvas.width = img.width;
                            this.canvas.height = img.height;
                            let ctx = this.canvas.getContext("2d");
                            ctx.drawImage(img, 0, 0);
            
                            let src = cv.imread(this.canvas);

                            let orb = new cv.ORB();
                            let keypoints = new cv.KeyPointVector();
                            let descriptors = new cv.Mat();
                            orb.detectAndCompute(src, new cv.Mat(), keypoints, descriptors);
            
                            // 特徴点を `img.src` をキーとして格納
                            this.features[path] = { keypoints, descriptors };
                            cv.imshow("_" + path.replace(".png",""),src)

                            src.delete();
                            gray.delete();
                            orb.delete();
                            keypoints.delete();
                            //descriptors.delete(); ここで開放するとbf.matchができない
            
                            // `resolve` を呼び出してプロミスを完了
                            resolve();
                        };
                    });
                });
            
                // すべての画像の読み込みが完了したら特定のコードを実行
                Promise.all(loadPromises).then(() => {
                    console.log("すべての画像の特徴点抽出が完了しました");
                    navigator.mediaDevices.getUserMedia({
                        video: {
                            width: { ideal: 360 },
                            height: { ideal: 510 },
                            aspectRatio: 360 / 510
                        }
                    }).then(stream => {
                        this.video.srcObject = stream;
            
                        this.video.onloadedmetadata = () => {
                            this.video.width = this.video.videoWidth;
                            this.video.height = this.video.videoHeight;
                            this.intervalID = setInterval(() => this.cameraFeatureComparison(), 1000); // 1秒ごとにマッチングを行う
                        };
                    }).catch(err => {
                        console.error("カメラの起動に失敗しました: " + err);
                    });
                });
            }
            cameraFeatureComparison() {
                this.canvas.width = this.video.videoWidth;
                this.canvas.height = this.video.videoHeight;
                let ctx = this.canvas.getContext("2d");
                ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);

                let src = cv.imread(this.canvas);  // canvas から画像データを読み込む

                let orb = new cv.ORB();  // ORB オブジェクトの作成
                let keypoints = new cv.KeyPointVector();  // キーポイント格納用
                let descriptors = new cv.Mat();  // 特徴量の格納用
                orb.detectAndCompute(src, new cv.Mat(), keypoints, descriptors);  // 特徴点と特徴量を抽出

                // 画像の特徴点とカメラの特徴点をマッチング
                for (let path in this.features) {
                    let feature = this.features[path];
                    let bf = new cv.BFMatcher(cv.NORM_HAMMING, true);  // マッチャー作成
                    let matches = new cv.DMatchVector();
                    
                    // bf.match を呼び出す前に descriptors の解放をしない
                    bf.match(descriptors, feature.descriptors, matches);  // マッチング処理
                    matchImagesWithORB(descriptors, feature.descriptors)

                    let totalKeypoints = keypoints.size();  // キーポイントの数
                    let matchedKeypoints = matches.size();  // マッチングされたキーポイント数
                    let matchRatio = (matchedKeypoints / totalKeypoints) * 100;  // 一致率の計算

                    // 結果を HTML に表示
                    document.getElementById(path.replace(".png", "")).textContent = `${matchRatio.toFixed(2)}%`;

                    // 使用後にオブジェクトを削除
                    matches.delete();
                    bf.delete();
                }

                // 必要なくなったオブジェクトの削除
                src.delete();  // 読み込んだ画像
                gray.delete();  // グレースケール画像
                orb.delete();  // ORB オブジェクト
                keypoints.delete();  // キーポイント
                descriptors.delete();  // 特徴量
            }

        }

        function matchImagesWithORB(img1, img2) {
            // グレースケール変換
            const gray1 = new cv.Mat();
            const gray2 = new cv.Mat();
            cv.cvtColor(img1, gray1, cv.COLOR_RGBA2GRAY, 0);
            cv.cvtColor(img2, gray2, cv.COLOR_RGBA2GRAY, 0);

            // ORBを使って特徴点と記述子を検出
            const orb = new cv.ORB();
            const keypoints1 = new cv.KeyPointVector();
            const keypoints2 = new cv.KeyPointVector();
            const descriptors1 = new cv.Mat();
            const descriptors2 = new cv.Mat();

            orb.detectAndCompute(gray1, new cv.Mat(), keypoints1, descriptors1);
            orb.detectAndCompute(gray2, new cv.Mat(), keypoints2, descriptors2);

            // FLANNベースのマッチャーを使って特徴点をマッチング
            const FLANN_INDEX_LSH = 6;
            const indexParams = new cv.FlannBasedMatcher([FLANN_INDEX_LSH, 20, 10]);
            const searchParams = new cv.Mat();

            const flann = new cv.FlannBasedMatcher(indexParams, searchParams);
            const matches = new cv.DMatchVector();

            flann.knnMatch(descriptors1, descriptors2, matches, 2);

            // 比率テストで適切なマッチだけを残す
            const goodMatches = new cv.DMatchVector();
            for (let i = 0; i < matches.size(); i++) {
                let match = matches.get(i);
                if (match.get(0).distance < 0.75 * match.get(1).distance) {
                    goodMatches.push_back(match.get(0));
                }
            }

            // マッチング結果を描画
            const outputImg = new cv.Mat();
            cv.drawMatches(img1, keypoints1, img2, keypoints2, goodMatches, outputImg);

            // 結果を表示
            cv.imshow('canvasOutput', outputImg);

            // メモリ解放
            gray1.delete();
            gray2.delete();
            orb.delete();
            keypoints1.delete();
            keypoints2.delete();
            descriptors1.delete();
            descriptors2.delete();
            matches.delete();
            goodMatches.delete();
            outputImg.delete();
        }

    </script>
</body>
</html>


