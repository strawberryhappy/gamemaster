<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>特徴点マッチング</title>
    <script async src="https://docs.opencv.org/4.x/opencv.js" type="text/javascript"></script>
</head>
<body>
    <h1>カメラ映像と画像の特徴点マッチング</h1>
    <video id="video" autoplay></video>
    <canvas id="canvas" style="display: none;"></canvas>
    
    <!-- 結果表示用の要素 -->
    <div>
        <div>市民: <span id="citizen">- %</span></div>
        <div>人狼: <span id="werewolf">- %</span></div>
    </div>

    <script>
        class gamemaster {
            constructor(paths){
                this.video = document.getElementById("video");
                this.canvas = document.getElementById("canvas");

                this.intervalID;
            
                this.images = [];
                this.features = {};
                
                this.addFeatures(paths || ["citizen.png","werewolf.png"]);
            }

            addFeatures(imagePaths) {
                // 画像の読み込みプロミスを格納する配列
                const loadPromises = imagePaths.map(path => {
                    return new Promise(resolve => {
                        this.images.push(path);

                        const img = new Image();
                        img.src = path;
            
                        img.onload = () => {
                            this.canvas.width = img.width;
                            this.canvas.height = img.height;
                            const ctx = this.canvas.getContext("2d");
                            ctx.drawImage(img, 0, 0);
            
                            const src = cv.imread(this.canvas);
                            const gray = new cv.Mat();
                            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
            
                            const orb = new cv.ORB();
                            const keypoints = new cv.KeyPointVector();
                            const descriptors = new cv.Mat();
                            orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors);
            
                            // 特徴点を `img.src` をキーとして格納
                            this.features[path] = { keypoints, descriptors };
            
                            src.delete();
                            gray.delete();
                            orb.delete();
                            keypoints.delete();
                            //descriptors.delete(); ここで開放するとbf.matchができない
            
                            // `resolve` を呼び出してプロミスを完了
                            resolve();
                        };
                    });
                });
            
                // すべての画像の読み込みが完了したら特定のコードを実行
                Promise.all(loadPromises).then(() => {
                    console.log("すべての画像の特徴点抽出が完了しました");
                    navigator.mediaDevices.getUserMedia({
                        video: {
                            width: { ideal: 360 },
                            height: { ideal: 510 },
                            aspectRatio: 360 / 510
                        }
                    }).then(stream => {
                        this.video.srcObject = stream;
            
                        this.video.onloadedmetadata = () => {
                            this.video.width = this.video.videoWidth;
                            this.video.height = this.video.videoHeight;
                            this.intervalID = setInterval(() => this.cameraFeatureComparison(), 1000); // 1秒ごとにマッチングを行う
                        };
                    }).catch(err => {
                        console.error("カメラの起動に失敗しました: " + err);
                    });
                });
            }
            cameraFeatureComparison() {
                this.canvas.width = this.video.videoWidth;
                this.canvas.height = this.video.videoHeight;
                const ctx = this.canvas.getContext("2d");
                ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);

                const src = cv.imread(this.canvas);  // canvas から画像データを読み込む
                const gray = new cv.Mat();  // グレースケール画像用
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);  // カラー画像をグレースケールに変換

                const orb = new cv.ORB();  // ORB オブジェクトの作成
                const keypoints = new cv.KeyPointVector();  // キーポイント格納用
                const descriptors = new cv.Mat();  // 特徴量の格納用
                orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors);  // 特徴点と特徴量を抽出

                // 画像の特徴点とカメラの特徴点をマッチング
                for (const path in this.features) {
                    let feature = this.features[path];
                    const bf = new cv.BFMatcher(cv.NORM_HAMMING, true);  // マッチャー作成
                    const matches = new cv.DMatchVector();
                    
                    // bf.match を呼び出す前に descriptors の解放をしない
                    bf.match(descriptors, feature.descriptors, matches);  // マッチング処理

                    const totalKeypoints = keypoints.size();  // キーポイントの数
                    const matchedKeypoints = matches.size();  // マッチングされたキーポイント数
                    const matchRatio = (matchedKeypoints / totalKeypoints) * 100;  // 一致率の計算

                    // 結果を HTML に表示
                    document.getElementById(path.replace(".png", "")).textContent = `${matchRatio.toFixed(2)}%`;

                    // 使用後にオブジェクトを削除
                    matches.delete();
                    bf.delete();
                }

                // 必要なくなったオブジェクトの削除
                src.delete();  // 読み込んだ画像
                gray.delete();  // グレースケール画像
                orb.delete();  // ORB オブジェクト
                keypoints.delete();  // キーポイント
                descriptors.delete();  // 特徴量
            }

        }
    </script>
</body>
</html>
